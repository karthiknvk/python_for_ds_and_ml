{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SPARK LECTURE</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>spark is one of the latest technologies being used to quickly and easily handle big data</li>\n",
    "<li>MapReduce writes most of its data to disk after each map and reduce operation spark on the other hand keeps most the data in memory after each transformation spark can spill over the disk if the memory is filled</li>\n",
    "<li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RTT operations <br>\n",
    "1)transformations<br>\n",
    "2)actions.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>ACTIONS<li>\n",
    "<ol>\n",
    "<li>COLLECT -> return all the elements of the R D D as an array at the driver program.</li>\n",
    "<li>COUNT -> is going to return a number of elements in the RTD.</li>\n",
    "<li>FIRST -> will return the first element in the RTT </li>\n",
    "<li>TAKE -> we'll return an array of the first and elements of the RTT.</li>\n",
    "</ol>\n",
    "\n",
    "<li>TRANSFORMATIONS<li>\n",
    "<ol>\n",
    "<li>FILTER[RDD.filter()] -> applies a function to each element and returns elements that evaluate to TRUE.<i>[just like Python's built in filter function]</i> </li>\n",
    "<li>MAP[RDD.map()] -> transforms each element and preserves the same number of elements.<i>[really similar idea to those that apply you map some sort of function to every element in the RDD]</i></li>\n",
    "<li>FLATMAP[RDD.flatMap()] -> is going to transform each element into zero through and elements and will actually probably change the number of elements from your original already the two after he performed the flat map operation.</li>\n",
    "</ol>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>RDD PAIRS</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They'll have a key and a value. (key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This usually offers better partitioning of data and it leads to functionality based off of a reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>OTHER METHODS</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)REDUCE [Reduce()] -> going to perform an action that will aggregate our DD elements using a function that returns a single elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)REDUCE BY KEY [ReduceByKey()]-> is an action that will aggregate pair RDD elements using a function that returns a pair RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
